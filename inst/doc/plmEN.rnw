%\VignetteIndexEntry{Introduction to plm}
\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{url}
\usepackage{Sweave}
\title{Introduction to plm}

\author{Yves Croissant \& Giovanni Millo}
\begin{document}

\maketitle


\section{Introduction}

The aim of package \texttt{plm} is to provide an easy way to estimate
panel models. Some panel models may be estimated with package \texttt{nlme}
(\textit{non--linear mixed effect models}), but not in an intuitive
way for an econometrician.
\texttt{plm} provides methods to read panel data, to estimate a wide
range of models and to make some tests. 
This library is loaded using :

<<>>=
library(plm)
@ 

This document illustrates the features  of  \texttt{plm}, using
data available in  package \texttt{Ecdat}. 

<<>>=
library(Ecdat)
@ 

These data are used in  \textsc{Baltagi} (2001).

\section{Reading data}

With \texttt{plm}, data are stored in an object of class
\texttt{pdata.frame},  which is a \texttt{data.frame} with additional
attributes describing the structure of the data set.
A \texttt{pdata.frame} may be created from an ordinary \texttt{data.frame}
using the \texttt{pdata.frame} function or from a text file using the
\texttt{pread.table} function.


\subsection{Reading the data from a data.frame}

We illustrate the use of the \texttt{pdata.frame} function with the
\texttt{Produc} data :


<<>>=
data(Produc)
pdata.frame(Produc,"state","year","pprod")
@ 

The  \texttt{pdata.frame} function has  4 arguments :

\begin{itemize}
\item the name of the  \texttt{data.frame},
\item \texttt{id} : the individual index,
\item \texttt{time} : the time index,
\item \texttt{name} : the name under which the \texttt{pdata.frame}
  will be stored.
\end{itemize}

Observations are assumed to be sorted by individuals first, and by
period. The third argument is optional, if \texttt{NULL} a new
variable called \texttt{time} is added. The fourth argument is also
optional, if \texttt{NULL} the \texttt{pdata.frame} is stored under
the same name as the \texttt{data.frame}.


<<>>=
data(Hedonic)
pdata.frame(Hedonic,"townid")
@ 

In case of a balanced panel, the \texttt{id} may be the number of
individuals. In this case, two new variables (called \texttt{id} and
\texttt{time}) are added.

<<>>=
data(Wages)
pdata.frame(Wages,595)
@ 

A description of the data is obtained using the \texttt{summary}
method :

<<>>=
summary(Hedonic)
@ 

The printing consists on four sections :

\begin{itemize}
\item \texttt{indexes} indicates the names of the index variables,
\item \texttt{panel dimensions} gives information about the dimension
  of the panel,
\item \texttt{Time/individual variation} indicates whether some
  variables have only individual or time variation,
\item \texttt{Descriptive statistics} gives descriptive statistics
  about the variables.
\end{itemize}

\subsection{Reading the data from a text file}

\texttt{pread.table} reads panel data from a text file, with the
following syntax : 

\begin{verbatim}
pread.table("c:/mes documents/essai/mydata.txt",
         "firm","year","dataname",header=T,sep=";",dec=",")
\end{verbatim}

The arguments of  \texttt{pread.table} are :

\begin{itemize}
\item the text file,
\item \texttt{id} : the individual index,
\item \texttt{time} : the time index,
\item \texttt{name} : the name under which the  \texttt{pdata.frame}
  will be stored  (if \texttt{NULL}, the name of the \texttt{pdata.frame}
  is the name of the file without the path and the extension),
\item further arguments that will be passed to  \texttt{read.table}.
\end{itemize}




\section{Model estimation}

\texttt{plm} provides four functions for estimation :

\begin{itemize}
\item \texttt{plm} : estimation of the
  basic panel models, \emph{i.e.} within, between and random effect
  models. Models are estimated using the \texttt{lm} function to
  transformed data,
\item \texttt{pvcm} : estimation of models with variable coefficients,
\item \texttt{pgmm} : estimation of general method of moments models,
\item \texttt{pggls} : estimation of general feasible generalized least squares
  models.
\end{itemize}

All these functions share the same 4 first arguments :

\begin{itemize}
\item \texttt{formula} : the symbolic description of the model to be estimated,
\item \texttt{data} : the \texttt{pdata.frame} containing the data,
\item \texttt{effect} : the kind of effects to include in the model,
  \emph{i.e.} individual effects, time effects or both,
\item \texttt{model} : the kind of model to be estimated, most of the
time a model with fixed effects or a model with random effects.
\end{itemize}

The results of this four functions are stored in an object which class has the
same name of the function. They all inherit from class \texttt{panelmodel}. A
\texttt{panelmodel} object contains : \texttt{coefficients},
\texttt{residuals}, \texttt{fitted.values}, \texttt{vcov},
\texttt{df.residual} and \texttt{call}.

Functions that extract these elements and to print the object are provided.




\subsection{Estimation of the basic models with plm}

There are two ways to use \texttt{plm} : the first one is to estimate
a list of models (the default behavior), the second to estimate just one model.
In the first case, the estimated models are :

\begin{itemize}
\item the fixed effects model (\texttt{within}),
\item the pooling model (\texttt{pooling}),
\item the between model (\texttt{between}),
\item the error components model (\texttt{random}).
\end{itemize}

The basic use of \texttt{plm} is to indicate the model formula and the \texttt{pdata.frame}
\footnote{The following example is from \textsc{Baltagi} (2001), pp. 25--28.} :

<<>>=
zz <- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=pprod)
@ 

The result of the estimation is stored in a \texttt{plms} object which
is a list of 4 estimated models, each of them being objects of class \texttt{plm}.
Each individual model can be easily extracted :

<<>>=
zzwith <- zz$within
@ 

A particular model to be estimated may also be indicated by filling
the \texttt{model} argument of \texttt{plm}.

<<>>=
zzra <- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=pprod,model="random")
@ 


<<>>=
print(zzra)
@ 

\texttt{summary} and \texttt{print.summary} methods are provided. 

\begin{itemize}
\item for  \texttt{plms} objects, coefficients and standard errors
  of the fixed effects and the error components models are printed,
\item for  \texttt{plm} object, the table of coefficients and some
  statistics are printed.
\end{itemize}


<<>>=
summary(zz)
summary(zzra)
@ 

For a \texttt{random} model, the \texttt{summary} method gives
information about the variance of the components of the errors.

\texttt{plm} objects can be updated using the \texttt{update} method :

<<>>=
zzwithmod <- update(zzwith,.~.-unemp-log(emp)+emp)
zzmod <- update(zz,.~.-unemp-log(emp)+emp)
summary(zzwithmod)
@ 

Fixed effects may be extracted easily from a \texttt{plms} or a
\texttt{plm} object using  \texttt{FE} :

<<>>=
FE(zzmod)[1:10]
@ 

The \texttt{FE} function returns an object of class \texttt{FE}. A
summary method is provided, which prints the effects (in deviation
from the overall intercept), their standard
errors and the test of equality to the overall intercept.

<<>>=
summary(FE(zzmod))[1:10,]
@ 


\subsection{More advanced use of plm}


\subsubsection{Options for the random effect model}

The random effect model is obtained as a linear estimation on
quasi--differentiated  data. The parameter of this transformation is
obtained using preliminary estimations. Four estimators of this
parameter are available, depending on the value of the argument \texttt{random.method}  :

\begin{itemize}
\item \texttt{swar} : from \textsc{Swamy} and \textsc{Arora}
  (1972), the default value,
\item \texttt{walhus} : from \textsc{Wallace} and \textsc{Hussain} (1969),
\item \texttt{amemiya} : from \textsc{Amemiyia} (1971),
\item \texttt{nerlove} : from \textsc{Nerlove} (1971).
\end{itemize}

For exemple, to use the \texttt{amemiya} estimator :

<<>>=
zzra <- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=pprod,model="random",random.method="amemiya")
@ 


\subsubsection{Choosing  the effects}

The default behavior of \texttt{plm} is to introduce individual
effects. Using the \texttt{effect} argument, one may also introduce :

\begin{itemize}
\item time effects (\texttt{effect="time"}),
\item individual and time effects (\texttt{effect="twoways"}).
\end{itemize}

For example, to estimate a two--ways effect model for the
\texttt{Grunfeld} data :

<<>>=
data(Grunfeld)
pdata.frame(Grunfeld,"firm","year")
z <- plm(inv~value+capital,data=Grunfeld,effect="twoways",random.method="amemiya")
summary(z$random)

@ 

In the ``effects'' section of the result is printed now the variance
of the three elements of the error term and the three parameters used
in the transformation. 

The two--ways effect model is for the moment only available for
balanced panels.


\subsubsection{Hausman--Taylor's model}

\textsc{Hausman}--\textsc{Taylor}'s model may be estimated with \texttt{plm}
by equating the \texttt{model} argument to  \texttt{"ht"} and
filling the second argument \texttt{instruments} with a formula
indicating the variables used as instruments.


<<>>=
data(Wages)
pdata.frame(Wages,595)
form=lwage~wks+south+smsa+married+exp+I(exp^2)+bluecol+ind+union+sex+black+ed
ht=plm(form,data=Wages,instruments=~sex+black+bluecol+south+smsa+ind,model="ht")
summary(ht)

@ 

\subsubsection{Instrumental variables estimation}

One or all of the models may be estimated using instrumental variables
by indicating the list of the instrumental variables. This can be done
using one of the two following techniques :

\begin{itemize}
\item specifying the total list of instruments  (using the
  \texttt{instruments} argument of \texttt{plm}),
\item specifying, on the one hand the external instruments in the argument
  \texttt{instrument} and on  the other hand the variables of the
  model that are assumed to be endogenous in the argument \texttt{endog}.
\end{itemize}

The instrumental variables estimator used may be indicated with the
\texttt{inst.method} argument :
\begin{itemize}
\item \texttt{bvk}, from  \textsc{Balestra} and
  \textsc{Varadharajan--Krishnakumar} (1987), the default value,
\item \texttt{baltagi}, from \textsc{Baltagi} (1981).
\end{itemize}

We illustrate instrumental variables estimation with the
\texttt{Crime} data\footnote{See
  \textsc{Baltagi} (2001), pp.119--120.}. 
The same estimation is done using the first syntax  (\texttt{cr1}) and
the second (\texttt{cr2}). The  \texttt{prbarr} and \texttt{polpc}
variables are
assumed to be endogenous and there are two external instruments \texttt{taxpc} and \texttt{mix} :

<<>>=
data(Crime)
pdata.frame(Crime,"county","year")
form=log(crmrte)~log(prbarr)+log(polpc)+log(prbconv)+log(prbpris)+log(avgsen)+log(density)+log(wcon)+log(wtuc)+log(wtrd)+log(wfir)+log(wser)+log(wmfg)+log(wfed)+log(wsta)+log(wloc)+log(pctymle)+log(pctmin)+region+smsa+year
inst=~log(prbconv)+log(prbpris)+log(avgsen)+log(density)+log(wcon)+log(wtuc)+log(wtrd)+log(wfir)+log(wser)+log(wmfg)+log(wfed)+log(wsta)+log(wloc)+log(pctymle)+log(pctmin)+region+smsa+log(taxpc)+log(mix)+year
inst2=~log(taxpc)+log(mix)
endog=~log(prbarr)+log(polpc)
cr=plm(form,data=Crime)
cr1=plm(form,data=Crime,instruments=inst)
cr2=plm(form,data=Crime,instruments=inst2,endog=endog)
summary(cr2$random)

@ 



\subsubsection{Unbalanced panel}

\texttt{plm} enables the estimation of unbalanced panel data, with a
few restrictions (twoways effects models are not supported and the
only transformation for random effects models is \texttt{swar}).

The
following example is based on the \texttt{Hedonic} data\footnote{See \textsc{Baltagi}
  (2001), p. 174.}:

<<>>=
form=mv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+blacks+lstat
ba=plm(form,data=Hedonic)
summary(ba$random)

@ 


\subsection{Variable coefficients model}

The \texttt{pvcm} function enables the estimation of variable
coefficients models. Time or individual effects are introduced if
\texttt{effect} is fixed to \texttt{"time"} or \texttt{"individual"}
(the default value). 

Coefficients are assumed to be fixed if \texttt{model="within"} and
random if \texttt{model="random"}. In the first case, a different
model is estimated for each individual (or time period). In the second
case, the \textsc{Swamy} (1970) model is estimated. It is a
generalized least squares model which use the result of the previous model.


With the \texttt{Grunfeld} data, we get :

<<>>=
znp <- pvcm(inv~value+capital,data=Grunfeld,model="within")
znp 
summary(znp)
@ 

<<>>=
form <- inv~value+capital
sw <- plm(form,data=Grunfeld,model="random")
summary(sw)
@ 

\subsection{General method of moments estimator}

The general method of moments is provided by the \texttt{pgmm}
function. It's main argument is  a \texttt{dynformula} which describe the variables of the model and the lag structure.


The effect argument is either \texttt{NULL}, \texttt{"individual"} (the default),
or \texttt{"twoways"}. In the first case, the
model is estimated in levels. In the second case, the model is
estimated in first differences to get rid of the individuals
effects. In the last case, the model is estimated in first differences
and time dummies are included. 

In a gmm estimation, there are ``normal'' instruments and ``gmm'' instruments. gmm instruments are indicated with the \texttt{gmm.inst} argument (a one side formula) and the lags by with the \texttt{lag.gmm} argument. By default, all the variables of the model that are not used as gmm instruments are used as normal instruments, with the same lag structure. 

The complete list of instruments can also be specified with the
argument \texttt{instruments} which should be a one side formula (or \texttt{dynformula}). 


The \texttt{model} argument specifies whether a one--step or a
two--steps model is required (\texttt{"onestep"} or \texttt{"twosteps"}).

The  following example is from \textsc{Arellano} (2003). Employment in
different firms is explained by past values of employment and wages
(two lags). All available lags are used up to $t-2$.

<<>>=
data(Snmesp)
pdata.frame(Snmesp,"firm","year")
z <-  pgmm(dynformula(n~w,lag=list(c(1,2),c(1,2))),effect="twoways",model="twosteps",Snmesp,gmm.inst=~n+w,
          lag.gmm=c(2,99),transformation=c("d"))
summary(z)
@ 

In the following example, a pure auto--regressive model is
estimated.

<<>>=
z <-  pgmm(dynformula(n~1,lag=list(c(1,2))),effect="twoways",model="twosteps",Snmesp,gmm.inst=~n,
          lag.gmm=c(2,99),transformation=c("d"))
summary(z)
@ 

\subsection{General FGLS models}
General FGLS estimators are based on a two-step estimation process: first an OLS model is estimated, then its residuals are used to estimate an error covariance matrix for use in a feasible-GLS analysis. Formally, the structure of the error covariance matrix is $ V=I_N \otimes \Omega $, with symmetry being the only requisite for $\Omega$: $ \Omega(ij)=\Omega(ji) $ (see Wooldridge (2002), 10.4.3 and 10.5.5).

This framework allows the error covariance structure inside every group (if \texttt{effect="individual"}) of observations to be fully unrestricted and is therefore robust against any type of intragroup heteroskedasticity and serial correlation. This structure, by converse, is assumed identical across groups and thus \texttt{ggls} is inefficient under groupwise heteroskedasticity. Cross-sectional correlation is excluded a priory.

Moreover, the number of variance parameters to be estimated with $NT$ data points is $T(T+1)/2$, which makes these estimators particularly suited for situations where $N>>T$, as e.g. in labour or household income surveys, while problematic for "long" panels. 

In a pooled time series context (\texttt{effect="time"}), symmetrically, this estimator is able to account for arbitrary cross-sectional correlation, provided that the latter is time-invariant (see Greene (2003) 13.9.1-2, p.321-2). In this case serial correlation has to be assumed away and the estimator is consistent with respect to the time dimension, keeping N fixed.

The function \texttt{pggls} estimates general FGLS models, with either fixed of ''random'' effects\footnote{The ''random effect'' is better termed ''general FGLS'' model, as in fact it does not have a proper random effects structure, but we keep this terminology for consistency with \texttt{plm}.}. 

The ''random effect'' general FGLS is estimated by
 
<<>>=
zz <- pggls(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=pprod,model="random")
summary(zz)
@ 

The fixed effects \texttt{pggls} (see \textsc{Wooldridge} (2002, p.276)) is based on estimation of a within model in the first step; the rest follows as above. It is estimated by

<<>>=
zz <- pggls(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=pprod,model="within")
summary(zz)
@ 

The \texttt{pggls} function is similar to \texttt{plm} in many respects (e.g., Hausman tests may be carried out on \texttt{pggls} objects much the same way they are done on \texttt{plm} ones). An exception is that the estimate of the group covariance matrix of errors (\verb!zz$sigma!, 17x17 matrix, not shown) is reported in the model objects instead of the usual estimated variances of the two error components.

\section{Tests}


\subsection{Tests of poolability}

\texttt{pooltest} tests the hypothesis that the same coefficients
apply to each individual. It is a standard F test, based on the
comparison of a model obtained for the full sample and a model based
on the estimation of an equation for each individual. The main
argument of \texttt{pooltest} is a \texttt{plms} or a \texttt{plm} object. 
The second argument is a \texttt{pvcm} object obtained with \texttt{model=within} .
If the first argument is a \texttt{plms} object, 
a third argument  \texttt{effect} should be fixed to \texttt{FALSE} if
the intercepts are assumed to be identical (the default value) or \texttt{TRUE} if
not\footnote{The following examples are from 
  \textsc{Baltagi} (2001), pp. 57--58.}.

<<>>=

form=inv~value+capital
znp=pvcm(form,data=Grunfeld,model="within")
zplm=plm(form,data=Grunfeld)
pooltest(zplm,znp)
pooltest(zplm,znp,effect=T)
pooltest(zplm$within,znp)

z=plm(form,data=Grunfeld,effect="time")
znpt=pvcm(form,data=Grunfeld,effect="time",model="within")
pooltest(z,znpt,effect=F)

@


\subsection{Tests for individual and time effects}



\subsubsection{Lagrange multiplier tests}

\texttt{plmtest} implements tests of individual or/and time effects  based on the results
of the pooling model. It's main argument is a
\texttt{plm} object (the result of a pooling model) or a
\texttt{plms} object.

Two additional arguments can be added to indicate the kind of test to
be computed. The argument \texttt{type} is whether :

\begin{itemize}
\item \texttt{bp} : \textsc{Breusch--Pagan} (1980), the default value,
\item \texttt{honda} : \textsc{Honda} (1985),
\item \texttt{kw} : \textsc{King} and \textsc{Wu} (1997).
\end{itemize}

The effects tested are indicated with the  \texttt{effect} argument :

\begin{itemize}
\item \texttt{individual} for individual effects  (the default value),
\item \texttt{time} for time effects,
\item \texttt{twoways} for individuals and time effects.
\end{itemize}

Some examples of the use of \texttt{plmtest} are shown below\footnote{See \textsc{Baltagi} (2001), p. 65.}:

<<>>=
library(Ecdat)
g <- plm(inv ~ value + capital, data=Grunfeld)
plmtest(g)
plmtest(g,effect="time")
plmtest(g,type="honda")
plmtest(g,type="ghm",effect="twoways")
plmtest(g,type="kw",effect="twoways")
@ 

\subsubsection{F tests}

\texttt{pFtest} computes F tests of effects based on the comparison of
the  \texttt{within} and the \texttt{pooling} models. Its arguments
are whether a \texttt{plms} object or two \texttt{plm} objects
(the results of a  \texttt{pooling} and a \texttt{within} model).
Some examples of the use of \texttt{pFtest} are shown below\footnote{See \textsc{Baltagi} (2001),
  p. 65.}:

<<>>=
library(Ecdat)
gi <- plm(inv ~ value + capital, data=Grunfeld)
gt <- plm(inv ~ value + capital, data=Grunfeld,effect="time")
gd <- plm(inv ~ value + capital, data=Grunfeld,effect="twoways")
pFtest(gi)
pFtest(gi$within,gi$pooling)
pFtest(gt)
pFtest(gd)

@ 



\subsection{Hausman's test}

\texttt{phtest} computes the \textsc{Hausman}'s test which is based on
the  comparison of two models. It's main argument may be :

\begin{itemize}
\item a \texttt{plms} object. In this case, the two models used in the
  test are the \texttt{within} and the \texttt{random} models (the
  most usual case with panel data),
\item two \texttt{plm} objects.
\end{itemize}


Some examples of the use of \texttt{phtest} are shown below
\footnote{See \textsc{Baltagi} (2001), p. 71.}:


<<>>=
g <- plm(inv~value+capital,data=Grunfeld)
phtest(g)
phtest(g$between, g$random)

@ 


\subsection{Robust covariance matrix estimation}
Robust estimators of the covariance matrix of coefficients are provided, mostly for use in Wald-type tests. \texttt{pvcovHC} estimates three ''flavours'' of White (1980, 1984)'s heteroskedasticity-consistent covariance matrix (known as the \emph{sandwich} estimator). Interestingly, in the context of panel data the most general version also proves consistent vs. serial correlation.

All types assume no correlation between errors of different groups while allowing for heteroskedasticity across groups, so that the full covariance matrix of errors is $  V=I_n \otimes \Omega_i;  i=1,..,n$. As for the \emph{intragroup} error covariance matrix of every single group of observations, \texttt{"white1"} allows for general heteroskedasticity but no serial correlation, i.e

\begin{equation}
 \label{eq:omegaW1}
 \Omega_i=
 \left[ \begin{array}{c c c c}
 \sigma_{i1}^2 & \dots & \dots & 0 \\
 0 & \sigma_{i2}^2 & & \vdots \\
 \vdots & & \ddots & 0 \\
 0 & & & \sigma_{iT}^2 \\
 \end{array} \right]
\end{equation}

while \texttt{"white2"} is \texttt{"white1"} restricted to a common variance inside every group, estimated as $\sigma_i^2=\sum_{t=1}^T{e_{it}^2}/T$, so that $\Omega_i=I_T \otimes \sigma_i^2$ (see Greene (2003), 13.7.1-2 and Wooldridge (2003), 10.7.2); \texttt{"arellano"} (see ibid. and the original ref. Arellano (1987)) allows a fully general structure w.r.t. heteroskedasticity and serial correlation:

\begin{equation}
 \label{eq:omegaArellano}
 \Omega_i=
 \left[ \begin{array}{c c c c c}
 \sigma_{i1}^2 & \sigma_{i1,i2}  & \dots & \dots & \sigma_{i1,iT} \\
 \sigma_{i2,i1} & \sigma_{i2}^2 & & & \vdots \\
 \vdots & & \ddots & & \vdots \\
 \vdots & & & \sigma_{iT-1}^2 & \sigma_{iT-1,iT} \\
 \sigma_{iT,i1} & \dots & \dots & \sigma_{iT,iT-1} & \sigma_{iT}^2 \\
 \end{array} \right]
\end{equation}

The latter is, as already observed, consistent w.r.t. timewise correlation of the errors, but on the converse, unlike the White 1 and 2 methods, it relies on large N asymptotics with small T. 

The errors may be weighted according to the schemes proposed by MacKinnon and White (1985) and Cribari-Neto (2004) to improve small-sample performance. 

Main use of \texttt{pvcovHC} is together with testing functions from \texttt{lmtest} and \texttt{car} packages. These typically allow passing the \texttt{vcov} parameter to be either a matrix or a function (see Zeileis 2004). If one is happy with the defaults, it is easiest to pass the function itself:

<<>>=
library(lmtest)
data(Airline)
pdata.frame(Airline,"airline","year")
form <- log(cost)~log(output)+log(pf)+lf
z <- plm(form,data=Airline,model="within")
coeftest(z,pvcovHC)
@

else one may do the covariance computation inside the call to \texttt{coeftest}, thus passing on a matrix:

<<>>=
coeftest(z,pvcovHC(z,type="white2",weights="HC3"))
@ 

For some tests, e.g. for multiple model comparisons by \texttt{waldtest}, one should always provide a function\footnote{Joint zero-restriction testing still allows providing the \texttt{vcov} of the unrestricted model as a matrix, see the documentation of package \texttt{lmtest}}. In this case, optional parameters are provided as shown below (see also Zeileis, 2004, p.12):

<<>>=
waldtest(z,update(z,.~.-log(pf)-lf),
  vcov=function(x) pvcovHC(x,type="white2",weights="HC3"))
@ 

\texttt{linear.hypothesis} from package \texttt{car} may be used to test for linear restrictions:

<<>>=
library(car)
linear.hypothesis(zz, "2*log(pc)=log(emp)", vcov=pvcovHC)
@

\section{References}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.4cm}

  Amemiyia, T. (1971), The estimation of the variances in a
  variance--components model, \emph{International Economic Review}, 12,
  pp.1--13.

  Arellano M. (1987), Computing robust standard errors for within group estimators, 
\emph{Oxford bulletin of Economics and Statistics}, \textbf{49}, 431--434.


  Arellano, M. (2003), Panel data econometrics, Oxford University Press.

  Arellano M. and S. Bond (1991), Some tests of specification for
  panel data : monte carlo evidence and an application to employment
  equations, \emph{Review of Economic Studies}, 58, pp.277--297.

  Balestra, P. and J. Varadharajan--Krishnakumar (1987), Full
  information estimations of a system of simultaneous equations with
  error components structure, \emph{Econometric Theory}, 3, pp.223--246.
  
  Baltagi, B.H. (1981), Simultaneous equations with error components,
  \emph{Journal of econometrics}, 17, pp.21--49.
  
  Baltagi, B.H. (2001) \emph{Econometric Analysis of Panel Data}. John
  Wiley and sons. ltd.

  Breusch, T.S. and A.R. Pagan (1980), The Lagrange multiplier test and
  its applications to model specification in econometrics, \emph{Review
    of Economic Studies}, 47, pp.239--253.

  Cribari-Neto F. (2004), Asymptotic inference under heteroskedasticity
of unknown form. \emph{Computational Statistics \& Data Analysis}
\textbf{45}, 215--233.

  Gourieroux, C., A. Holly and A. Monfort (1982), Likelihood ratio test,
  Wald test, and Kuhn--Tucker test in linear models with inequality
  constraints on the regression parameters, \emph{Econometrica}, 50,
  pp.63--80.

  Greene W. H. (2003), \emph{Econometric Analysis}, 5th ed. Prentice Hall.

  Hausman, G. (1978), Specification tests in econometrics,
  \emph{Econometrica}, 46, pp.1251--1271.

  Hausman, J.A. and W.E. Taylor (1981), Panel data and unobservable
  individual effects, \emph{Econometrica}, 49, pp.1377--1398.
  
  Honda, Y. (1985), Testing the error components model with non--normal
  disturbances, \emph{Review of Economic Studies}, 52, pp.681--690.

  King, M.L. and P.X. Wu (1997), Locally optimal one--sided tests for
  multiparameter hypotheses, \emph{Econometric Reviews}, 33,
  pp.523--529.

  MacKinnon J. G., White H. (1985), Some heteroskedasticity-consistent
covariance matrix estimators with improved finite sample properties.
\emph{Journal of Econometrics} \textbf{29}, 305--325.

  Nerlove, M. (1971), Further evidence on the estimation of dynamic
  economic relations from a time--series of cross--sections,
  \emph{Econometrica}, 39, pp.359--382.

  Swamy, P.A.V.B. (1970), Efficient inference in a random coefficient
  regression model, \emph{Econometrica}, 38, pp.311-323.

  
  Swamy, P.A.V.B. and S.S. Arora (1972), The exact finite sample
  properties of the estimators of coefficients in the error components
  regression models, \emph{Econometrica}, 40, pp.261--275.

  Wallace, T.D. and A. Hussain (1969), The use of error components
  models in combining cross section with time series data,
  \emph{Econometrica}, 37(1), pp.55--72.

  White H. (1980), \emph{Asymptotic Theory for Econometricians}, Ch. 6, Academic Press, Orlando (FL).

  White H. (1984), A heteroskedasticity-consistent covariance matrix and
a direct test for heteroskedasticity. \emph{Econometrica} \textbf{48},
817--838.

  Wooldridge J. M. (2003), \emph{Econometric Analysis of Cross Section and Panel Data}, MIT Press

  Zeileis A. (2004), Econometric Computing with HC and HAC Covariance Matrix
Estimators. \emph{Journal of Statistical Software}, \textbf{11}(10), 1--17.

URL \url{http://http://www.jstatsoft.org/v11/i10/}.

\end{document}


% <!-- Local IspellDict: english --> <!-- Local IspellPersDict: ~/emacs/.ispell-english -->
